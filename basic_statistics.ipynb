{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Basics\n",
    "N: Total Population (not generally realistic)\\\n",
    "n: Total sample from population\\\n",
    "M: Successes in **population**\\\n",
    "x: Successes in **sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def mode(*args):\n",
    "    dict_vals = {i:args.count(i) for i in args}\n",
    "    max_list = [k for k,v in dict_vals.items() if v == max(dict_vals.values())]\n",
    "    return max_list\n",
    "mode(1,2,4,3,3,3,4,5,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Charts\n",
    "# Histogram: bars connected to each other, visualising distribution of a continuous quantitative variable\n",
    "# Bar Graph: Like histogram but with categorical data\n",
    "# Pareto Chart: Bars, x-axis has categorical data, ordered in descending by y value. And line overlayed across, showing cumulative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Variance & SD\n",
    "# Measure of how data is spread around mean\n",
    "# Population Variance (simga**2)\n",
    "# Sample Variance (s**2)\n",
    "# Formula:\n",
    "# S**2 = (SUM (( x[i] - mean )**2)) / (n-1)  # n-1 as almost always evaluating against sample rather than population\n",
    "def variance(x_list):\n",
    "    mean = sum(x_list) / len(x_list)\n",
    "    return sum([(x-mean)**2 for x in x_list]) / (len(x_list)-1)\n",
    "sample = [2,3,4,5,6]\n",
    "variance(sample)\n",
    "\n",
    "# # Standard Deviation\n",
    "# Large SD = Large spread of values\n",
    "# Sqrt of variance (essentially removing the **2 applied when calculating x-mean)\n",
    "def std_dev(x_list):\n",
    "    return math.sqrt(variance(x_list))\n",
    "std_dev(sample)\n",
    "\n",
    "# # Coefficient of Variation\n",
    "# Used to compare multiple datasets (to scale them)\n",
    "# Formula:\n",
    "# std_dev / mean\n",
    "sd_miles_dataset = .6455\n",
    "mean_miles_dataset = 3.75\n",
    "sd_kms_dataset = 1.038\n",
    "mean_kms_dataset = 6.03\n",
    "\n",
    "miles_dataset_coefficient = sd_miles_dataset / mean_miles_dataset\n",
    "kms_dataset_coefficient = sd_kms_dataset / mean_kms_dataset\n",
    "miles_dataset_coefficient == miles_dataset_coefficient # True, both .1721\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrkt_cap</th>\n",
       "      <th>earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1532</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft</th>\n",
       "      <td>1488</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amz</th>\n",
       "      <td>1343</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goog</th>\n",
       "      <td>928</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb</th>\n",
       "      <td>615</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mrkt_cap  earnings\n",
       "apple          1532        58\n",
       "microsoft      1488        35\n",
       "amz            1343        75\n",
       "goog            928        41\n",
       "fb              615        17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Covariance:\n",
    "# Shows if 2 groups/columns/variables of data are moving in the same direction\n",
    "# Formula:\n",
    "# cov = SUM ( (x[i]-x_mean) * (y[i]-y_mean) ) / (n-1)\n",
    "# > 0: Moving together\n",
    "# < 0: Moving opposite\n",
    "# = 0: Independent\n",
    "companies_df = pd.DataFrame.from_dict({'apple':[1532,58],'microsoft':[1488,35],'amz':[1343,75],'goog':[928,41],'fb':[615,17]},orient='index',columns=['mrkt_cap','earnings']) \n",
    "companies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5803.200000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cov(x_list,y_list):\n",
    "    if len(x_list) != len(y_list):\n",
    "        return 'Lists must be of equal length'\n",
    "    n = len(x_list)\n",
    "    x_mean = sum(x_list) / n\n",
    "    y_mean = sum(y_list) / n\n",
    "    return sum([(x-x_mean)*(y-y_mean) for x,y in zip(x_list,y_list)]) / (n-1)\n",
    "\n",
    "cov(companies_df.mrkt_cap,companies_df.earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.660125602195931"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Correlation Coefficient\n",
    "# Adjusts COV to see relationship between x & y\n",
    "# -1 < r < 1  : 1 = Perfect correlation, 0 = Independent, -1 = Perfect negative correlation\n",
    "# Formula:\n",
    "# r = COV(X,Y) / (std_dev(X),std_dev(Y))\n",
    "def r_corr_coeff(x_list,y_list):\n",
    "    return cov(x_list,y_list) / (std_dev(x_list)*std_dev(y_list))\n",
    "\n",
    "r_corr_coeff(companies_df.mrkt_cap,companies_df.earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-normalised mean: 4.0\n",
      "Pre-normalised SD: 1.5811388300841898\n",
      "Normalised mean: 0.0\n",
      "Normalised SD: 1.0\n"
     ]
    }
   ],
   "source": [
    "# # Standard Normal Distribution\n",
    "# When data forms a bell curve\n",
    "# 1SD represents 68% of data, 2SD 95%, 3SD 98%\n",
    "# SD of 1 when calculating on all data\n",
    "# Mean = Mode = Median = 0\n",
    "# 50% of values lie either side of Mean\n",
    "\n",
    "# Normalizing data:\n",
    "# For each x: (x-mean) / sd\n",
    "x_list = [1,2,4,4,4,5,5,5,6]\n",
    "print(f'Pre-normalised mean: {sum(x_list)/len(x_list)}')\n",
    "print(f'Pre-normalised SD: {std_dev(x_list)}')\n",
    "\n",
    "def normalise(x_list):\n",
    "    mean = sum(x_list)/len(x_list)\n",
    "    sd = std_dev(x_list)\n",
    "    return [(x-mean)/sd for x in x_list]\n",
    "\n",
    "normalised_x_list = normalise(x_list)\n",
    "# Below rounded as actual results very slightly off, noticable at 10+ decimal places\n",
    "print(f'Normalised mean: {round(sum(normalised_x_list)/len(normalised_x_list),4)}')\n",
    "print(f'Normalised SD: {round(std_dev(normalised_x_list),4)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence that value will fall between 2,667,402.35 and 15,290,226.05\n"
     ]
    }
   ],
   "source": [
    "# # Central Limit Theorem\n",
    "# The more samples taken, the closer data gets to mean and to normal distribution\n",
    "\n",
    "# # Standard Error\n",
    "# Measures accuracy of an estimate\n",
    "# Formula: SD / sqrt(n)\n",
    "\n",
    "# # Z score\n",
    "# translates SD to percentile\n",
    "# Eg. If wanting 95%, z score \n",
    "# Formula: z = x-mean / sd\n",
    "# eg. x = 48, mean = 40.8, sd = 3.5\n",
    "# z = x-mean/sd = 2.06\n",
    "# z-score table 2.06 -> 0.98 (98%th percentile)\n",
    "# 98% of data under curve falls before x=48\n",
    "\n",
    "# # Confidence Intervals\n",
    "# Point estimates can be inaccurate, alternative is intervals \n",
    "# eg. 3 sample means (5.5,6,5.6), could instead say they lie in interval(5,7)\n",
    "# Confidence, can be 90, 95, 99\n",
    "# 90% confidence = 9/10 intervals to contain mean value.\n",
    "# Alpha = doubt = 1-confidence\n",
    "# eg. mean salary in football league Â£8.9million\n",
    "def example_confidence_interval():\n",
    "    mean = 8978814.2\n",
    "    confidence = .95\n",
    "    a = 1-confidence\n",
    "    critical_probability = 1-a/2\n",
    "    z_score_of_crit_p = 1.96\n",
    "    sd = 12471425\n",
    "    n = 15\n",
    "    return (mean+z_score_of_crit_p*(sd/math.sqrt(n)),mean-z_score_of_crit_p*(sd/math.sqrt(n)))\n",
    "example_confidence_interval()\n",
    "print(f'95% confidence that value will fall between {example_confidence_interval()[1]:,.2f} and {example_confidence_interval()[0]:,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence that mean pop value will fall between 61,693km and 63,219km. So below the manufacturers promise of 65,000km\n"
     ]
    }
   ],
   "source": [
    "# # Student's T Distribution\n",
    "# Used when sample sizes are small and/or variance in unknown\n",
    "# Looks like a normal distribution but has fatter/higher tails on both ends\n",
    "# Eg. Manufacturer says break pads will last 65,000km, 95% confidence\n",
    "# eg cont. our data collected shows mean 62,456.2 instead, SD = 2418.4\n",
    "# degrees of freedom (n-1) = 30 samples, -1 = 29\n",
    "# as confidence .95, lookup 29 dof on T table with .95, t value = 1.699\n",
    "def example_t_distribution():\n",
    "    mean = 62456.2\n",
    "    tvalue = 1.699 # dof 29; confidence .95\n",
    "    sd = 2418.4\n",
    "    n = 30\n",
    "    return (mean+(tvalue*(sd/math.sqrt(n-1))),mean-(tvalue*(sd/math.sqrt(n-1))))\n",
    "\n",
    "example_t_distribution()\n",
    "print(f'95% confidence that mean pop value will fall between {example_t_distribution()[1]:,.0f}km and {example_t_distribution()[0]:,.0f}km. So below the manufacturers promise of 65,000km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute value of z-score 8.997454879355836\n",
      "Critical value: 1.96\n"
     ]
    }
   ],
   "source": [
    "# # Dependent Samples:\n",
    "# 1 Sample can use used to determine other results (cause and effect)\n",
    "# ie. weekly reuslts of weight lifting at the end of a week\n",
    "\n",
    "# # Independent Samples:\n",
    "# Samples have no relation to other\n",
    "# ie. 10 random blood samples at lab A and 10 random at lab B\n",
    "# ie. 1 random group gets drug, other group gets placebo\n",
    "\n",
    "# # Testing a Hypothesis\n",
    "# Hypothesis, educated guess which *can be tested*\n",
    "# Null Hypothesis or H0: Hypothesis to test\n",
    "# Eg. Avg used car price us between 19k and 21k\n",
    "# Alternative Hypothesis or H1: All other possibilites\n",
    "# Eg. Avg used car price is NOT between 19k and 21k\n",
    "\n",
    "# Probability of rejecting the null hypothesis when it is true = Significance level (alpha)\n",
    "# Common alphas: .01, .05, .1\n",
    "# If sample mean & population mean are equal, Z = 0\n",
    "# Rejection of Null Hypothesis would be found at 1 - (alpha/2) \n",
    "# 1 - (.05/2) = .975\n",
    "# .975 on z table = 1.96 SDs\n",
    "# Rejected region will be less than or greater than 1.96 from mean on bell curve\n",
    "\n",
    "# One-sided test:\n",
    "# Eg. Avg used car price > 21k\n",
    "# a = .05 (not /2 as not considering both sides with a one-sided test)\n",
    "# 1 - 0.05 = 0.95\n",
    "# 0.95 on z table = 1.65 SDs\n",
    "\n",
    "# # Hypothesis Errors\n",
    "# Type I Errors: Rejecting a True H0 \n",
    "# Type II Errors: Accepting a False H0 # Generally caused by poor sampling\n",
    "# Power of the Test: Increase by increasing samples\n",
    "\n",
    "# # Mean Testing\n",
    "# When wanting to calculate if sample is higher or lower than population mean\n",
    "# Pop mean = H0 = eg. Break pads last 64,000km\n",
    "pop_mean = 64000\n",
    "sample = [58500,58700,62800,57220,62750,59370,57720,60920,61910,59260,63550,60520,58710,57340,60660,57750,60430,60050,62970,58870]\n",
    "mean = sum(sample)/len(sample)\n",
    "sd = std_dev(sample)\n",
    "n = len(sample)\n",
    "sample_error = sd / math.sqrt(n)\n",
    "# Standardise means\n",
    "sample_z_score = abs(mean-pop_mean)/sample_error\n",
    "confidence = .95\n",
    "alpha = (1-confidence)/2 # 2-sided test\n",
    "z_for_lookup = 1 - alpha\n",
    "sd_from_z = 1.96 # critical_z_score: 0.975, looked up on z table, result 1.96\n",
    "print(f'Absolute value of z-score {sample_z_score}')\n",
    "print(f'Critical value: {sd_from_z}')\n",
    "print('As 8.99 is greater than 1.96, reject null hypothesis. So with a .95 confidence level, can reject that the break pads have a life span of 64,000km')\n",
    "\n",
    "# # P Value\n",
    "# Smallest level of significance at which we reject the hypothesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Linear Regression\n",
    "# Fitting a line/equation to sample data with a linear relationship\n",
    "# Example:\n",
    "# Data:\n",
    "temp_sales = pd.DataFrame([  [37,292],\n",
    "                [40,228],\n",
    "                [49,324],\n",
    "                [61,376],\n",
    "                [72,440],\n",
    "                [79,496],\n",
    "                [83,536],\n",
    "                [81,556],\n",
    "                [75,496],\n",
    "                [64,412], \n",
    "                [53,324], \n",
    "                [40,320]\n",
    "            ], columns=['temp','sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = temp_sales.temp\n",
    "y_list = temp_sales.sales\n",
    "def linear_regression(x_list,y_list):\n",
    "    x_mean = sum(x_list)/len(x_list)\n",
    "    y_mean = sum(y_list)/len(y_list)\n",
    "    x_diffs_from_mean = [x-x_mean for x in x_list]\n",
    "    y_diffs_from_mean = [y-y_mean for y in y_list]\n",
    "    multiplied_xy_resids = [x_resid * y_resid for x_resid,y_resid in zip(x_diffs_from_mean,y_diffs_from_mean)]\n",
    "    x_resids_squared = [x_resid**2 for x_resid in x_diffs_from_mean]\n",
    "    slope = sum(multiplied_xy_resids) / sum(x_resids_squared)\n",
    "    y_intercept = y_mean - slope * x_mean\n",
    "    return [(y_intercept+(xi*slope)) for xi in x_list]\n",
    "temp_sales['newy'] =  linear_regression(x_list,y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A correlation of 1 would mean a perfect correlation between x and y (temp and sales).\n",
      "        The r correlation coefficient is 0.96. As this is very close to 1, the regression line will tightly match the data. \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# # Covariance and Correlation Coefficient applied to Regression\n",
    "cov(x_list,y_list)\n",
    "r = r_corr_coeff(x_list,y_list)\n",
    "print(f'''A correlation of 1 would mean a perfect correlation between x and y (temp and sales).\n",
    "        The r correlation coefficient is {r:.2}. As this is very close to 1, the regression line will tightly match the data. \n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the regression line eliminates 92.5% of the error. Therefore in this case it certianly makes sense to calculate the regression line.\n"
     ]
    }
   ],
   "source": [
    "# # Regression Line vs Mean Line\n",
    "# Is it worth calculating the regression line vs just using the mean\n",
    "# **Coefficient of Detemination** answers this\n",
    "# Compares area (resid**2) from regression line to values vs mean line to values\n",
    "def coefficient_of_determination(x_list,y_list):\n",
    "    regression_line = linear_regression(x_list,y_list)\n",
    "    mean_line = [sum(y_list)/len(y_list) for y in y_list]\n",
    "    resids_to_regression_line = [(y-r)**2 for y,r in zip(y_list,regression_line)]\n",
    "    resids_to_mean_line = [(y-m)**2 for y,m in zip(y_list,mean_line)]\n",
    "    return (sum(resids_to_mean_line) - sum(resids_to_regression_line)) / sum(resids_to_mean_line)\n",
    "\n",
    "cod = coefficient_of_determination(x_list,y_list)\n",
    "print(f'Using the regression line eliminates {cod:.1%} of the error. Therefore in this case it certianly makes sense to calculate the regression line.')\n",
    "\n",
    "# Note: using r2 coefficient or determination may be misleading as an increasing r2 may just mean overfitting rather than a better generalised model.\n",
    "# To revisit after reviewings adjusted r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1 SD (68% of sample points), the regression line will be off at most by +- 22.0%\n",
      "In other words, 68% of values will be between lines [199.68211306893366, 213.62360478473593, 255.44807993214263, 311.2140467953516, 362.3328497532931, 394.862997090165, 413.45165271123466, 404.1573249006998, 376.27434146909536, 325.1555385111538, 274.0367355532123, 213.62360478473593] and [312.3420561153564, 334.14928822495267, 399.57098455374137, 486.7999129921264, 566.7597640606459, 617.6433056497038, 646.7196151291655, 632.1814603894346, 588.5669961702422, 508.6071451017226, 428.647294033203, 334.14928822495267]\n",
      "95% of values will be between lines [143.35214154572233, 153.36076306462758, 183.38662762134328, 223.42111369696423, 260.11939259961673, 283.4728428103956, 296.81767150226926, 290.14525715633243, 270.12801411852195, 233.42973521586944, 196.7314563132169, 153.36076306462758] and [368.6720276385677, 394.412129945061, 471.6324368645407, 574.5928460905137, 668.9732212143222, 729.0334599294731, 763.3535963381308, 746.193528133802, 694.7133235208155, 600.3329483970069, 505.95257327319837, 394.412129945061]\n",
      "97.5% of values will be between lines [87.02217002251099, 93.09792134451924, 111.32517531054391, 135.62818059857685, 157.90593544594034, 172.0826885306262, 180.18369029330387, 176.13318941196505, 163.98168676794856, 141.70393192058506, 119.42617707322155, 93.09792134451924] and [425.001999161779, 454.6749716651693, 543.69388917534, 662.385779188901, 771.1866783679985, 840.4236142092425, 879.9875775470962, 860.2055958781693, 800.8596508713888, 692.0587516922913, 583.2578525131937, 454.6749716651693]\n"
     ]
    }
   ],
   "source": [
    "# # Root Mean Squared Deviation\n",
    "# Difference between samples and the regression line\n",
    "# Formula:\n",
    "# RMSD = SUM(y-y_mean)**2 / n-1\n",
    "def root_mean_sq_dev(x_list,y_list):\n",
    "    regression_line = linear_regression(x_list,y_list)\n",
    "    resids_to_regression_line = [(y-r)**2 for y,r in zip(y_list,regression_line)]\n",
    "    return math.sqrt(sum(resids_to_regression_line) / (n-1))\n",
    "rmsd = root_mean_sq_dev(x_list,y_list)\n",
    "print(f'For 1 SD (68% of sample points), the regression line will be off at most by +- {rmsd:.3}%')\n",
    "print(f'In other words, 68% of values will be between lines {[i*(1-(rmsd/100)) for i in linear_regression(x_list,y_list)]} and {[i*(1+(rmsd/100)) for i in linear_regression(x_list,y_list)]}')\n",
    "print(f'95% of values will be between lines {[i*(1-((rmsd/100)*2)) for i in linear_regression(x_list,y_list)]} and {[i*(1+((rmsd/100)*2)) for i in linear_regression(x_list,y_list)]}')\n",
    "print(f'97.5% of values will be between lines {[i*(1-((rmsd/100)*3)) for i in linear_regression(x_list,y_list)]} and {[i*(1+((rmsd/100)*3)) for i in linear_regression(x_list,y_list)]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nba</th>\n",
       "      <th>mlb</th>\n",
       "      <th>nfl</th>\n",
       "      <th>nhl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18-29yo</th>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33-44yo</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nba  mlb  nfl  nhl\n",
       "18-29yo   23   12   24    7\n",
       "33-44yo   12   13   45    6"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Chi Square Tests\n",
    "# Required Conditions:\n",
    "# - Data must be random, large (each cell has value > 5) & independent [target less than 10% of pop] (sample with replacement [ person/thing is put back in for picking again after being picked]\n",
    "# Chi Square Test of Homogeniety:\n",
    "# When wanting to find relationship between different categories of variables\n",
    "# Sample 2 groups to compare probability distributions\n",
    "# Example:\n",
    "# H0 = Age doesn't affect favourite sport\n",
    "# H1 = Age foes affect favourite sport\n",
    "data = [\n",
    "    [23,12,24,7],\n",
    "    [12,13,45,6]\n",
    "]\n",
    "data_df = pd.DataFrame(data,columns=['nba','mlb','nfl','nhl'],index=['18-29yo','33-44yo'])\n",
    "# Expected values = (column_total * row_total) / overall_total\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nba</th>\n",
       "      <th>mlb</th>\n",
       "      <th>nfl</th>\n",
       "      <th>nhl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18-29yo</th>\n",
       "      <td>16.267606</td>\n",
       "      <td>11.619718</td>\n",
       "      <td>32.070423</td>\n",
       "      <td>6.042254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33-44yo</th>\n",
       "      <td>18.732394</td>\n",
       "      <td>13.380282</td>\n",
       "      <td>36.929577</td>\n",
       "      <td>6.957746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nba        mlb        nfl       nhl\n",
       "18-29yo  16.267606  11.619718  32.070423  6.042254\n",
       "33-44yo  18.732394  13.380282  36.929577  6.957746"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chi Table Expected Values\n",
    "n_rows = len(data_df)\n",
    "n_cols = len(data_df.columns)\n",
    "row_totals = data_df.sum(axis=1)\n",
    "col_totals = data_df.sum(axis=0)\n",
    "total = data_df.values.sum()\n",
    "\n",
    "expected = []\n",
    "for r in row_totals:\n",
    "    new_row = []\n",
    "    for c in col_totals:\n",
    "        new_row.append((c*r)/total)\n",
    "    expected.append(new_row)\n",
    "expected_df = pd.DataFrame(expected,columns=['nba','mlb','nfl','nhl'],index=['18-29yo','33-44yo'])\n",
    "expected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 degrees of freedom, the Chi Squared lookup table shows that a chi squared value of 9.307302948767479 falls between 0.05 & 0.025 alpha; therefore there is between 95% and 97.5% that the Null Hypothesys is correct (age does not affect favourite sport)\n"
     ]
    }
   ],
   "source": [
    "# Chi Square Test\n",
    "# Formula: \n",
    "# x2 = SUM ( (observed-expected)**2 / expected )\n",
    "def chi_square(observed_df,expected_df):\n",
    "    formula_applied_df = ((observed_df - expected_df)**2) / expected_df\n",
    "    degrees_of_freedom = (len(observed_df)-1) * (len(observed_df.columns)-1)\n",
    "    return formula_applied_df.values.sum(), degrees_of_freedom\n",
    "chisq,dof = chi_square(data_df,expected_df)\n",
    "\n",
    "print(f'Using {dof} degrees of freedom, the Chi Squared lookup table shows that a chi squared value of {chisq} falls between 0.05 & 0.025 alpha; therefore there is between 95% and 97.5% confidence that the Null Hypothesys is correct (age does not affect favourite sport)')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af6a2397ae482a303a21d2c2ea17a7825fd6a2fa4013e037c62f42bbf2800947"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
